{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# phase 0: compare old schema vs old data, output the summary in an excel file* to help decision making\n",
    "# phase 1: transform old schema to match (correct version) of old data\n",
    "# phase 2: compare phase 1 schema vs old data, output the summary in an excel file* to help decision making\n",
    "# phase 3: transform old data to match schema from phase 1 (doesn't count dependencies/required keywords)\n",
    "# phase 4: transform schema from phase 1 to match JSON Schema draft v7 (we will call it 'new schema')\n",
    "# phase 5: transform data from phase 2 to match the new schema (include all dependencies/required keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## common imports ##\n",
    "from os import path\n",
    "import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## common functions ##\n",
    "def fetch_mibig_json_filepaths(dir_path):\n",
    "    \"\"\"fetch mibig json paths from a specific folder\"\"\"\n",
    "    return glob.glob(path.join(dir_path, \"BGC*.json\"))\n",
    "\n",
    "def count_props(input_dict, cur_path, result):\n",
    "    \"\"\"given a (mibig?) json, construct a list of property paths\n",
    "    along with its presence count in the json object\"\"\"\n",
    "    key_path = cur_path\n",
    "    \n",
    "    if isinstance(input_dict, dict):\n",
    "        for key in input_dict.keys():\n",
    "            result = count_props(input_dict[key], \"{}/{}\".format(key_path, key), result)\n",
    "    elif isinstance(input_dict, list):\n",
    "        key_path = \"{}[]\".format(key_path)\n",
    "        for node in input_dict:\n",
    "            result = count_props(node, \"{}\".format(key_path), result)\n",
    "\n",
    "    if key_path not in result:\n",
    "        result[key_path] = 0\n",
    "    result[key_path] += 1\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def fetch_props_old_schema(input_dict, cur_path = \"\", result = {}):\n",
    "    \"\"\"given a (mibig?) json schema, construct a list of property paths\n",
    "    along with either required == True for each properties\"\"\"\n",
    "    key_path = cur_path\n",
    "    if (\"type\" not in input_dict) or (input_dict[\"type\"] not in [\"object\", \"array\"]):\n",
    "        key_path = \"{}\".format(cur_path) # string / etc.\n",
    "    elif input_dict[\"type\"] == \"object\":\n",
    "        for key in input_dict[\"properties\"]:\n",
    "            result = fetch_props_old_schema(input_dict[\"properties\"][key], \"{}/{}\".format(key_path, key), result)\n",
    "    elif input_dict[\"type\"] == \"array\":\n",
    "        key_path = \"{}[]\".format(cur_path)\n",
    "        result = fetch_props_old_schema(input_dict[\"items\"], \"{}\".format(key_path), result)\n",
    "    \n",
    "    if key_path not in result:\n",
    "        result[key_path] = \"required\" in input_dict and input_dict[\"required\"] == True\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### phase 0: compare old schema vs old data, output the summary in an excel file* to help decision making ########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_props = {}\n",
    "for json_path in sorted(fetch_mibig_json_filepaths(\"../../inputs/json_1.4/\")):\n",
    "    with open(json_path, \"r\") as json_file:\n",
    "        json_obj = json.load(json_file)\n",
    "        this_file_props = count_props(json_obj, \"\", {})\n",
    "        for prop in this_file_props:\n",
    "            if prop not in all_props:\n",
    "                all_props[prop] = [path.basename(json_path)]\n",
    "            else:\n",
    "                all_props[prop].append(path.basename(json_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File written: ../../preprocessed/old_schema_properties.csv\n",
      "File written: ../../preprocessed/old_data_vs_old_schema.csv\n"
     ]
    }
   ],
   "source": [
    "with open(\"../../inputs/mibig_schema.json\") as json_file:\n",
    "    json_obj = json.load(json_file)\n",
    "    schema_props = fetch_props_old_schema(json_obj)\n",
    "    with open(\"../../preprocessed/old_schema_properties.csv\", \"w\") as o:\n",
    "        for key in sorted(schema_props.keys()):\n",
    "            o.write(\"{},{}\\n\".format(key, schema_props[key]))\n",
    "        print(\"File written: {}\".format(o.name))\n",
    "    with open(\"../../preprocessed/old_data_vs_old_schema.csv\", \"w\") as o:\n",
    "        not_in_schema = []\n",
    "        for key in sorted(all_props.keys()):\n",
    "            if key not in schema_props.keys():\n",
    "                not_in_schema.append((key, all_props[key]))\n",
    "        for rep in sorted(not_in_schema, key=lambda x: len(x[1]), reverse = True):\n",
    "            o.write(\"{},{}\\n\".format(rep[0], len(rep[1])))\n",
    "        print(\"File written: {}\".format(o.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### phase 1: transform old schema to match (correct version) of old data ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File written: ../../preprocessed/mibig_schema_phase_1.json\n"
     ]
    }
   ],
   "source": [
    "# (everything is manually done)\n",
    "# update all comma-separated based properties into arrays\n",
    "# gene_pubs: integer --> gene_pubs: array\n",
    "print(\"File written: ../../preprocessed/mibig_schema_phase_1.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### phase 2: compare phase 1 schema vs old data, output the summary in an excel file* to help decision making ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File written: ../../preprocessed/schema_phase_1_properties.csv\n",
      "File written: ../../preprocessed/old_data_vs_schema_phase_1.csv\n",
      "File written: ../../preprocessed/bgc_to_fix_phase_2.csv\n"
     ]
    }
   ],
   "source": [
    "# use all_props from phase 0\n",
    "with open(\"../../preprocessed/mibig_schema_phase_1.json\") as json_file:\n",
    "    json_obj = json.load(json_file)\n",
    "    schema_props = fetch_props_old_schema(json_obj)\n",
    "    with open(\"../../preprocessed/schema_phase_1_properties.csv\", \"w\") as o:\n",
    "        for key in sorted(schema_props.keys()):\n",
    "            o.write(\"{},{}\\n\".format(key, schema_props[key]))\n",
    "        print(\"File written: {}\".format(o.name))\n",
    "    not_in_schema = []\n",
    "    for key in sorted(all_props.keys()):\n",
    "        if key not in schema_props.keys():\n",
    "            not_in_schema.append((key, all_props[key]))\n",
    "    with open(\"../../preprocessed/old_data_vs_schema_phase_1.csv\", \"w\") as o:\n",
    "        for rep in sorted(not_in_schema, key=lambda x: len(x[1]), reverse = True):\n",
    "            o.write(\"{},{}\\n\".format(rep[0], len(rep[1])))\n",
    "        print(\"File written: {}\".format(o.name))\n",
    "    with open(\"../../preprocessed/bgc_to_fix_phase_2.csv\", \"w\") as o:\n",
    "        bgc_to_fix = {}\n",
    "        for rep in not_in_schema:\n",
    "            for bgc in rep[1]:\n",
    "                if bgc not in bgc_to_fix:\n",
    "                    bgc_to_fix[bgc] = []\n",
    "                bgc_to_fix[bgc].append(rep[0])\n",
    "        for bgc in bgc_to_fix:\n",
    "            o.write(\"{},{}\\n\".format(bgc, \";\".join(bgc_to_fix[bgc])))\n",
    "        print(\"File written: {}\".format(o.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### phase 3: transform old data to match schema from phase 1 (doesn't count dependencies/required keywords) ####\n",
    "# (manually copy and do manual fixes)\n",
    "# automate for conversion of /general_params/Other/biosyn_class[] to /general_params/Other/other_subclass|\n",
    "for json_path in sorted(fetch_mibig_json_filepaths(\"../../preprocessed/json_1.4_phase_3/\")):\n",
    "    json_obj = None\n",
    "    with open(json_path, \"r\") as json_file:\n",
    "        json_obj = json.load(json_file)\n",
    "    if \"Other\" in json_obj[\"general_params\"] and \"biosyn_class\" in json_obj[\"general_params\"][\"Other\"]:\n",
    "        clas = json_obj[\"general_params\"][\"Other\"][\"biosyn_class\"][0]\n",
    "        del json_obj[\"general_params\"][\"Other\"][\"biosyn_class\"]\n",
    "        json_obj[\"general_params\"][\"Other\"][\"other_subclass\"] = clas\n",
    "        with open(json_path, \"w\") as json_file:\n",
    "            json.dump(json_obj, json_file)\n",
    "            print(\"Wrote {}\".format(json_path)) # will only be called once ever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify that all data matched schema\n",
    "all_props_phase_3 = {}\n",
    "for json_path in sorted(fetch_mibig_json_filepaths(\"../../preprocessed/json_1.4_phase_3/\")):\n",
    "    with open(json_path, \"r\") as json_file:\n",
    "        json_obj = json.load(json_file)\n",
    "        this_file_props = count_props(json_obj, \"\", {})\n",
    "        for prop in this_file_props:\n",
    "            if prop not in all_props_phase_3:\n",
    "                all_props_phase_3[prop] = [path.basename(json_path)]\n",
    "            else:\n",
    "                all_props_phase_3[prop].append(path.basename(json_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conflicts: 0\n"
     ]
    }
   ],
   "source": [
    "with open(\"../../preprocessed/mibig_schema_phase_1.json\") as json_file:\n",
    "    json_obj = json.load(json_file)\n",
    "    schema_props = fetch_props_old_schema(json_obj)\n",
    "    not_in_schema = []\n",
    "    for key in sorted(all_props_phase_3.keys()):\n",
    "        if key not in schema_props.keys():\n",
    "            not_in_schema.append((key, all_props_phase_3[key]))\n",
    "    print(\"Number of conflicts: {}\".format(len(not_in_schema)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### phase 4: transform schema from phase 1 to match JSON Schema draft v7 (we will call it 'new schema') ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_schema = None\n",
    "with open(\"../../preprocessed/mibig_schema_phase_1.json\") as json_file:\n",
    "    new_schema = json.load(json_file) # pre-load with old schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: fix 'required'\n",
    "def fix_required(input_dict):\n",
    "    if \"type\" in input_dict and input_dict[\"type\"] == \"object\":\n",
    "        input_dict[\"required\"] = []\n",
    "        for prop in input_dict[\"properties\"]:\n",
    "            child = input_dict[\"properties\"][prop]\n",
    "            if \"required\" in child and child[\"required\"] == True:\n",
    "                input_dict[\"required\"].append(prop)\n",
    "            fix_required(child)\n",
    "        if len(input_dict[\"required\"]) < 1:\n",
    "            del input_dict[\"required\"]\n",
    "    else:\n",
    "        if \"type\" in input_dict and input_dict[\"type\"] == \"array\":\n",
    "            fix_required(input_dict[\"items\"])\n",
    "        if \"required\" in input_dict:\n",
    "            del input_dict[\"required\"]\n",
    "fix_required(new_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2: fix 'dependencies'\n",
    "def fix_dependencies(input_dict):\n",
    "    if \"type\" in input_dict and input_dict[\"type\"] == \"object\":\n",
    "        input_dict[\"dependencies\"] = {}\n",
    "        for prop in input_dict[\"properties\"]:\n",
    "            child = input_dict[\"properties\"][prop]\n",
    "            if \"dependencies\" in child and isinstance(child[\"dependencies\"], str):\n",
    "                if child[\"dependencies\"] in input_dict[\"properties\"]:\n",
    "                    if child[\"dependencies\"] not in input_dict[\"dependencies\"]:\n",
    "                        input_dict[\"dependencies\"][child[\"dependencies\"]] = []\n",
    "                    input_dict[\"dependencies\"][child[\"dependencies\"]].append(prop)\n",
    "                else:\n",
    "                    print(\"Error: {} not found\".format(child[\"dependencies\"]))\n",
    "            fix_dependencies(child)\n",
    "        if len(input_dict[\"dependencies\"].keys()) < 1:\n",
    "            del input_dict[\"dependencies\"]\n",
    "    else:\n",
    "        if \"type\" in input_dict and input_dict[\"type\"] == \"array\":\n",
    "            fix_dependencies(input_dict[\"items\"])\n",
    "        if \"dependencies\" in input_dict:\n",
    "            del input_dict[\"dependencies\"]\n",
    "fix_dependencies(new_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3: make sure 'enum' contain unique items\n",
    "def fix_enum(input_dict):\n",
    "    if \"type\" in input_dict and input_dict[\"type\"] == \"object\":        \n",
    "        for prop in input_dict[\"properties\"]:\n",
    "            fix_enum(input_dict[\"properties\"][prop])\n",
    "    elif \"type\" in input_dict and input_dict[\"type\"] == \"array\":\n",
    "        fix_enum(input_dict[\"items\"])\n",
    "            \n",
    "    if \"enum\" in input_dict:\n",
    "        input_dict[\"enum\"] = list(set(input_dict[\"enum\"]))\n",
    "fix_enum(new_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5: manual curations\n",
    "new_schema[\"$schema\"] = \"http://json-schema.org/draft-07/schema#\"\n",
    "new_schema[\"$schema_version\"] = \"2.0\"\n",
    "new_schema[\"$schema_created\"] = \"20-03-2019\"\n",
    "\n",
    "#del new_schema[\"properties\"][\"general_params\"][\"dependencies\"]\n",
    "#new_schema[\"properties\"][\"general_params\"][\"allOf\"] = [\n",
    "#    {\n",
    "#        \"properties\": {\n",
    "#            \"biosyn_class\": {\"enum\": [\"Polyketide\"] }\n",
    "#        },\n",
    "#        \"required\": [\"Polyketide\"]\n",
    "#    }\n",
    "#]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4: save new schema\n",
    "with open(\"../../outputs/mibig_schema_draft7.json\", \"w\") as o:\n",
    "    o.write(json.dumps(new_schema, indent=4, separators=(',', ': ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
